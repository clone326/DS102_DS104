{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_science_salaries = pd.read_csv(\"Data Science and STEM Salaries.csv\")\n",
    "\n",
    "df_data_science_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_science_salaries.title.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing out the company counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = df_data_science_salaries.groupby(['company'])['timestamp'].count()\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Amazon\n",
    "\n",
    "sort_amazon_1 = df_data_science_salaries['company'].str.contains('A', na = False)\n",
    "sort_amazon_2 = df_data_science_salaries['company'].str.contains('a', na = False)\n",
    "sort_amazon_3 = df_data_science_salaries['company'].str.contains('M', na = False)\n",
    "sort_amazon_4 = df_data_science_salaries['company'].str.contains('m', na = False)\n",
    "sort_amazon_5 = df_data_science_salaries['company'].str.contains('Z', na = False)\n",
    "sort_amazon_6 = df_data_science_salaries['company'].str.contains('z', na = False)\n",
    "sort_amazon_7 = df_data_science_salaries['company'].str.contains('N', na = False)\n",
    "sort_amazon_8 = df_data_science_salaries['company'].str.contains('n', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_amazon_1 | sort_amazon_2) & (sort_amazon_3 | sort_amazon_4) & (sort_amazon_5 | sort_amazon_6) & (sort_amazon_7 | sort_amazon_8)].company.unique()\n",
    "\n",
    "# List of Amazon company name variations that needs standardisation:\n",
    "# Amazon\n",
    "# amazon\n",
    "# Amazon web services\n",
    "# amzon\n",
    "# Amzon\n",
    "# AMAZON\n",
    "# Amazon Web Services\n",
    "# Amazon.com\n",
    "# AMazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['amazon','Amazon web services','amzon','Amzon','AMAZON','Amazon Web Services','Amazon.com','AMazon'], value = 'Amazon', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_amazon_1 | sort_amazon_2) & (sort_amazon_3 | sort_amazon_4) & (sort_amazon_5 | sort_amazon_6) & (sort_amazon_7 | sort_amazon_8)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apple cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Apple\n",
    "\n",
    "sort_apple_1 = df_data_science_salaries['company'].str.contains('A', na = False)\n",
    "sort_apple_2 = df_data_science_salaries['company'].str.contains('a', na = False)\n",
    "sort_apple_3 = df_data_science_salaries['company'].str.contains('PP', na = False)\n",
    "sort_apple_4 = df_data_science_salaries['company'].str.contains('pp', na = False)\n",
    "sort_apple_5 = df_data_science_salaries['company'].str.contains('L', na = False)\n",
    "sort_apple_6 = df_data_science_salaries['company'].str.contains('l', na = False)\n",
    "sort_apple_7 = df_data_science_salaries['company'].str.contains('E', na = False)\n",
    "sort_apple_8 = df_data_science_salaries['company'].str.contains('e', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_apple_1 | sort_apple_2) & (sort_apple_3 | sort_apple_4) & (sort_apple_5 | sort_apple_6) & (sort_apple_7 | sort_apple_8)].company.unique()\n",
    "\n",
    "# List of Apple company name variations that needs standardisation:\n",
    "# Apple\n",
    "# apple\n",
    "# APPLE\n",
    "# Apple Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['apple', 'APPLE', 'Apple Inc.' ], value = 'Apple', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_apple_1 | sort_apple_2) & (sort_apple_3 | sort_apple_4) & (sort_apple_5 | sort_apple_6) & (sort_apple_7 | sort_apple_8)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloomberg cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Bloomberg\n",
    "\n",
    "sort_bloomberg_1 = df_data_science_salaries['company'].str.contains('BLOOMBERG', na = False)\n",
    "sort_bloomberg_2 = df_data_science_salaries['company'].str.contains('Bloomberg', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_bloomberg_1 | sort_bloomberg_2)].company.unique()\n",
    "\n",
    "# List of Bloomberg company name variations that needs standardisation:\n",
    "# BLOOMBERG LP\n",
    "# Bloomberg lp\n",
    "# Bloomberg LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['BLOOMBERG LP', 'Bloomberg lp', 'Bloomberg LP' ], value = 'Bloomberg', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_bloomberg_1 | sort_bloomberg_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Booking.com cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Booking.com\n",
    "\n",
    "sort_booking_1 = df_data_science_salaries['company'].str.contains('Booking', na = False)\n",
    "sort_booking_2 = df_data_science_salaries['company'].str.contains('BOOKING', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_booking_1 | sort_booking_2)].company.unique()\n",
    "\n",
    "# List of Booking company name variations that needs standardisation:\n",
    "# BOOKING.COM\n",
    "# Booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['BOOKING.COM', 'Booking'], value = 'Booking.com', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_booking_1 | sort_booking_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ByteDance cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of ByteDance\n",
    "\n",
    "sort_bytedance_1 = df_data_science_salaries['company'].str.contains('Byte', na = False)\n",
    "sort_bytedance_2 = df_data_science_salaries['company'].str.contains('byte', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_bytedance_1 | sort_bytedance_2)].company.unique()\n",
    "\n",
    "# List of ByteDance company name variations that needs standardisation:\n",
    "# bytedance\n",
    "# Bytedance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['bytedance', 'Bytedance'], value = 'ByteDance', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_bytedance_1 | sort_bytedance_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capital One cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Capital One\n",
    "\n",
    "sort_cap_one_1 = df_data_science_salaries['company'].str.contains('Capital', na = False)\n",
    "sort_cap_one_2 = df_data_science_salaries['company'].str.contains('capital', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_cap_one_1 | sort_cap_one_2)].company.unique()\n",
    "\n",
    "# List of Capital One company name variations that needs standardisation:\n",
    "# Capital one\n",
    "# capital one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Capital one', 'capital one'], value = 'Capital One', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_cap_one_2 | sort_cap_one_1)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cisco cleaning (We stopped here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Cisco\n",
    "\n",
    "sort_cisco_1 = df_data_science_salaries['company'].str.contains('Cisco', na = False)\n",
    "sort_cisco_2 = df_data_science_salaries['company'].str.contains('cisco', na = False)\n",
    "sort_cisco_3 = df_data_science_salaries['company'].str.contains('CISCO', na = False)\n",
    "sort_cisco_4 = df_data_science_salaries['company'].str.contains('CIsco', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_cisco_1 | sort_cisco_2 | sort_cisco_3 | sort_cisco_4)].company.unique()\n",
    "\n",
    "# List of Capital One company name variations that needs standardisation:\n",
    "# Cisco Systems\n",
    "# cisco systems\n",
    "# CISCO\n",
    "# Cisco Meraki\n",
    "# cisco\n",
    "# Cisco systems\n",
    "# CIsco\n",
    "# CISCO SYSTEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Cisco Systems', 'cisco systems', 'CISCO', 'Cisco Meraki','cisco', 'Cisco systems', 'CIsco', 'CISCO SYSTEMS' ], value = 'Cisco', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_cisco_1 | sort_cisco_2 | sort_cisco_3 | sort_cisco_4)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citi cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Citi\n",
    "\n",
    "sort_citi_1 = df_data_science_salaries['company'].str.contains('Citi', na = False)\n",
    "sort_citi_2 = df_data_science_salaries['company'].str.contains('citi', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_citi_1 | sort_citi_2)].company.unique()\n",
    "\n",
    "# List of Citi company name variations that needs standardisation:\n",
    "# Citibank\n",
    "# citi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Citibank', 'citi'], value = 'Citi', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_citi_1 | sort_citi_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dell cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Dell\n",
    "\n",
    "sort_dell_1 = df_data_science_salaries['company'].str.contains('Dell', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_dell_1)].company.unique()\n",
    "\n",
    "# List of Dell company name variations that needs standardisation:\n",
    "# Dell Technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Dell Technologies'], value = 'Dell', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_dell_1)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deloitte cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Deloitte\n",
    "\n",
    "sort_deloitte_1 = df_data_science_salaries['company'].str.contains('Deloitte', na = False)\n",
    "sort_deloitte_2 = df_data_science_salaries['company'].str.contains('deloitte', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_deloitte_1 | sort_deloitte_2)].company.unique()\n",
    "\n",
    "# List of Deloitte company name variations that needs standardisation:\n",
    "# Deloitte Consulting\n",
    "# Deloitte Consulting LLP\n",
    "# Deloitte Advisory\n",
    "# deloitte\n",
    "# Deloitte consulting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Deloitte Consulting', 'Deloitte Consulting LLP', 'Deloitte Advisory', 'deloitte', 'Deloitte consulting'], value = 'Deloitte', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_deloitte_1 | sort_deloitte_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disney cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Disney\n",
    "\n",
    "sort_disney_1 = df_data_science_salaries['company'].str.contains('Disney', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_disney_1)].company.unique()\n",
    "\n",
    "# List of Disney company name variations that needs standardisation:\n",
    "# The Walt Disney Company\n",
    "# Disney Streaming Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['The Walt Disney Company','Disney Streaming Services'], value = 'Disney', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_disney_1)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoorDash cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of DoorDash\n",
    "\n",
    "sort_doordash_1 = df_data_science_salaries['company'].str.contains('Doordash', na = False)\n",
    "sort_doordash_2 = df_data_science_salaries['company'].str.contains('DoorDash', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_doordash_1 | sort_doordash_2)].company.unique()\n",
    "\n",
    "# List of Doordash company name variations that needs standardisation:\n",
    "# Doordash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Doordash'], value = 'DoorDash', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_doordash_1 | sort_doordash_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eBay cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of eBay\n",
    "\n",
    "sort_ebay_1 = df_data_science_salaries['company'].str.contains('E', na = False)\n",
    "sort_ebay_2 = df_data_science_salaries['company'].str.contains('e', na = False)\n",
    "sort_ebay_3 = df_data_science_salaries['company'].str.contains('B', na = False)\n",
    "sort_ebay_4 = df_data_science_salaries['company'].str.contains('b', na = False)\n",
    "sort_ebay_5 = df_data_science_salaries['company'].str.contains('A', na = False)\n",
    "sort_ebay_6 = df_data_science_salaries['company'].str.contains('a', na = False)\n",
    "sort_ebay_7 = df_data_science_salaries['company'].str.contains('Y', na = False)\n",
    "sort_ebay_8 = df_data_science_salaries['company'].str.contains('y', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_ebay_1|sort_ebay_2) & (sort_ebay_3|sort_ebay_4) & (sort_ebay_5|sort_ebay_6) & (sort_ebay_7|sort_ebay_8)].company.unique()\n",
    "\n",
    "# List of eBay company name variations that needs standardisation:\n",
    "# ebay\n",
    "# Ebay\n",
    "# EBAY\n",
    "# EBay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['ebay', 'Ebay', 'EBAY', 'EBay'], value = 'eBay', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_ebay_1|sort_ebay_2) & (sort_ebay_3|sort_ebay_4) & (sort_ebay_5|sort_ebay_6) & (sort_ebay_7|sort_ebay_8)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPAM cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of EPAM\n",
    "\n",
    "sort_epam_1 = df_data_science_salaries['company'].str.contains('EPAM', na = False)\n",
    "sort_epam_2 = df_data_science_salaries['company'].str.contains('Epam', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_epam_1|sort_epam_2)].company.unique()\n",
    "\n",
    "# List of EPAM company name variations that needs standardisation:\n",
    "# Epam\n",
    "# EPAM Systems\n",
    "# Epam Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Epam', 'EPAM Systems', 'Epam Systems'], value = 'EPAM', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_epam_1|sort_epam_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ernst & Young cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Ernst & Young\n",
    "\n",
    "sort_ey_1 = df_data_science_salaries['company'].str.contains('Ernst', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_ey_1)].company.unique()\n",
    "\n",
    "# List of Ernst & Young company name variations that needs standardisation:\n",
    "# Ernst and young\n",
    "# Ernst and Young"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Ernst and young', 'Ernst and Young'], value = 'Ernst & Young', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_ey_1)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expedia cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Expedia\n",
    "\n",
    "sort_expedia_1 = df_data_science_salaries['company'].str.contains('Expedia', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_expedia_1)].company.unique()\n",
    "\n",
    "# List of Expedia company name variations that needs standardisation:\n",
    "# Expedia Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Expedia Group'], value = 'Expedia', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_expedia_1)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoDaddy cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of GoDaddy\n",
    "\n",
    "sort_godaddy_1 = df_data_science_salaries['company'].str.contains('Daddy', na = False)\n",
    "sort_godaddy_2 = df_data_science_salaries['company'].str.contains('daddy', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_godaddy_1 | sort_godaddy_2)].company.unique()\n",
    "\n",
    "# List of GoDaddy company name variations that needs standardisation:\n",
    "# Godaddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Godaddy'], value = 'GoDaddy', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_godaddy_1 | sort_godaddy_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goldman Sachs cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Goldman Sachs\n",
    "\n",
    "sort_goldmansachs_1 = df_data_science_salaries['company'].str.contains('Goldman', na = False)\n",
    "sort_goldmansachs_2 = df_data_science_salaries['company'].str.contains('GOLDMAN', na = False)\n",
    "sort_goldmansachs_3 = df_data_science_salaries['company'].str.contains('goldman', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_goldmansachs_1 |sort_goldmansachs_2 | sort_goldmansachs_3)].company.unique()\n",
    "\n",
    "# List of Goldman Sachs company name variations that needs standardisation:\n",
    "# GOLDMAN SACHS\n",
    "# goldman sachs\n",
    "# Goldman sachs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['GOLDMAN SACHS', 'goldman sachs', 'Goldman sachs'], value = 'Goldman Sachs', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_goldmansachs_1 |sort_goldmansachs_2 | sort_goldmansachs_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Google\n",
    "\n",
    "sort_google_1 = df_data_science_salaries['company'].str.contains('Google', na = False)\n",
    "sort_google_2 = df_data_science_salaries['company'].str.contains('GOogle', na = False)\n",
    "sort_google_3 = df_data_science_salaries['company'].str.contains('google', na = False)\n",
    "sort_google_4 = df_data_science_salaries['company'].str.contains('GOOGLE', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_google_1|sort_google_2|sort_google_3|sort_google_4)].company.unique()\n",
    "\n",
    "# List of Google company name variations that needs standardisation:\n",
    "# google\n",
    "# google llc\n",
    "# Google LLC\n",
    "# GOogle\n",
    "# \\xa0Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['google', 'google llc', 'Google LLC', 'GOogle', '\\xa0Google'], value = 'Google', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_google_1|sort_google_2|sort_google_3|sort_google_4)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of IBM\n",
    "\n",
    "sort_ibm_1 = df_data_science_salaries['company'].str.contains('Ibm', na = False)\n",
    "sort_ibm_2 = df_data_science_salaries['company'].str.contains('ibm', na = False)\n",
    "sort_ibm_3 = df_data_science_salaries['company'].str.contains('IBM', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_ibm_1|sort_ibm_2|sort_ibm_3)].company.unique()\n",
    "\n",
    "# List of IBM company name variations that needs standardisation:\n",
    "# Ibm\n",
    "# ibm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Ibm', 'ibm'], value = 'IBM', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_ibm_1|sort_ibm_2|sort_ibm_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intel cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Intel\n",
    "\n",
    "sort_intel_1 = df_data_science_salaries['company'].str.contains('Intel', na = False)\n",
    "sort_intel_2 = df_data_science_salaries['company'].str.contains('intel', na = False)\n",
    "sort_intel_3 = df_data_science_salaries['company'].str.contains('INTEL', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_intel_1|sort_intel_2|sort_intel_3)].company.unique()\n",
    "\n",
    "# List of Intel company name variations that needs standardisation:\n",
    "\n",
    "# Intel Corporation\n",
    "# intel\n",
    "# Intel corporation\n",
    "# INTEL corporation\n",
    "# intel corporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=['Intel Corporation','intel', 'Intel corporation', 'INTEL corporation', 'intel corporation'], value = 'Intel', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_intel_1|sort_intel_2|sort_intel_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPMorgan Chase cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of JPMorgan Chase\n",
    "\n",
    "sort_jpmorgan_1 = df_data_science_salaries['company'].str.contains('JPMorgan', na = False)\n",
    "sort_jpmorgan_2 = df_data_science_salaries['company'].str.contains('JPmorgan', na = False)\n",
    "sort_jpmorgan_3 = df_data_science_salaries['company'].str.contains('Jpmorgan', na = False)\n",
    "sort_jpmorgan_4 = df_data_science_salaries['company'].str.contains('JPMORGAN', na = False)\n",
    "\n",
    "replace_jp = df_data_science_salaries[(sort_jpmorgan_1|sort_jpmorgan_2|sort_jpmorgan_3|sort_jpmorgan_4)].company.unique()\n",
    "\n",
    "# List of JPMorgan Chase company name variations that needs standardisation:\n",
    "# JPMorgan\n",
    "# JPMORGAN\n",
    "# JPmorgan Chase\n",
    "# Jpmorgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=replace_jp, value = 'JPMorgan Chase', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_jpmorgan_1|sort_jpmorgan_2|sort_jpmorgan_3|sort_jpmorgan_4)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkedIn cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of LinkedIn\n",
    "\n",
    "sort_linkedin_1 = df_data_science_salaries['company'].str.contains('Linkedin', na = False)\n",
    "sort_linkedin_2 = df_data_science_salaries['company'].str.contains('LinkedIn', na = False)\n",
    "sort_linkedin_3 = df_data_science_salaries['company'].str.contains('linkedin', na = False)\n",
    "\n",
    "replace_linkedin = df_data_science_salaries[(sort_linkedin_1|sort_linkedin_2|sort_linkedin_3)].company.unique()\n",
    "\n",
    "replace_linkedin\n",
    "\n",
    "# List of LinkedIn company name variations that needs standardisation:\n",
    "# Linkedin\n",
    "# linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=replace_linkedin, value = 'LinkedIn', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_linkedin_1|sort_linkedin_2|sort_linkedin_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lockheed Martin cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Lockheed Martin\n",
    "\n",
    "sort_lockheed_1 = df_data_science_salaries['company'].str.contains('Lockheed', na = False)\n",
    "sort_lockheed_2 = df_data_science_salaries['company'].str.contains('lockheed', na = False)\n",
    "\n",
    "replace_lockheed = df_data_science_salaries[(sort_lockheed_1|sort_lockheed_2)].company.unique()\n",
    "\n",
    "replace_lockheed\n",
    "\n",
    "# List of Lockheed Martin company name variations that needs standardisation:\n",
    "# lockheed martin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace=replace_lockheed, value = 'Lockheed Martin', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_lockheed_1|sort_lockheed_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyft cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Lyft\n",
    "\n",
    "sort_lyft_1 = df_data_science_salaries['company'].str.contains('Lyft', na = False)\n",
    "sort_lyft_2 = df_data_science_salaries['company'].str.contains('lyft', na = False)\n",
    "\n",
    "replace_lyft = df_data_science_salaries[(sort_lyft_1|sort_lyft_2)].company.unique()\n",
    "\n",
    "replace_lyft\n",
    "\n",
    "# List of Lyft company name variations that needs standardisation:\n",
    "# lyft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_lyft, value = 'Lyft', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_lyft_1|sort_lyft_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microsoft cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_microsoft_1 = df_data_science_salaries['company'].str.contains('M', na = False)\n",
    "sort_mircosoft_2 = df_data_science_salaries['company'].str.contains('m', na = False)\n",
    "sort_microsoft_3 = df_data_science_salaries['company'].str.contains('F', na = False)\n",
    "sort_microsoft_4 = df_data_science_salaries['company'].str.contains('f', na = False)\n",
    "sort_microsoft_5 = df_data_science_salaries['company'].str.contains('T', na = False)\n",
    "sort_microsoft_6 = df_data_science_salaries['company'].str.contains('t', na = False)\n",
    "sort_microsoft_7 = df_data_science_salaries['company'].str.contains('S', na = False)\n",
    "sort_microsoft_8 = df_data_science_salaries['company'].str.contains('s', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_microsoft_1 | sort_mircosoft_2) & (sort_microsoft_3 | sort_microsoft_4) & (sort_microsoft_5 | sort_microsoft_6) & (sort_microsoft_7 | sort_microsoft_8)].company.unique()\n",
    "\n",
    "#For this microsoft issue, we will need to use the str.contains function and then do it 4 times with the \"or\" operator so that we can standardise company name\n",
    "\n",
    "# Microsoft\n",
    "# MICROSOFT\n",
    "# microsoft\n",
    "# MSFT\n",
    "# Msft\n",
    "# Microsoft Corporation\n",
    "# microsoft corporation\n",
    "# MIcrosoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = ['MICROSOFT', 'microsoft', 'MSFT', 'Msft', 'Microsoft Corporation', 'microsoft corporation', 'MIcrosoft' ], value = 'Microsoft', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_microsoft_1 | sort_mircosoft_2) & (sort_microsoft_3 | sort_microsoft_4) & (sort_microsoft_5 | sort_microsoft_6) & (sort_microsoft_7 | sort_microsoft_8)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Northrop Grumman cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Northrop Grumman\n",
    "\n",
    "sort_northrop_1 = df_data_science_salaries['company'].str.contains('Northrop', na = False)\n",
    "sort_northrop_2 = df_data_science_salaries['company'].str.contains('NORTHROP', na = False)\n",
    "\n",
    "replace_northrop = df_data_science_salaries[(sort_northrop_1|sort_northrop_2)].company.unique()\n",
    "\n",
    "replace_northrop\n",
    "\n",
    "# List of Northrop Grumman company name variations that needs standardisation:\n",
    "# NORTHROP GRUMMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_northrop, value = 'Northrop Grumman', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_northrop_1|sort_northrop_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nutanix cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Nutanix\n",
    "\n",
    "sort_nutanix_1 = df_data_science_salaries['company'].str.contains('Nutanix', na = False)\n",
    "sort_nutanix_2 = df_data_science_salaries['company'].str.contains('nutanix', na = False)\n",
    "\n",
    "replace_nutanix = df_data_science_salaries[(sort_nutanix_1|sort_nutanix_2)].company.unique()\n",
    "\n",
    "replace_nutanix\n",
    "\n",
    "# List of Nutanix company name variations that needs standardisation:\n",
    "# nutanix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_nutanix, value = 'Nutanix', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_nutanix_1|sort_nutanix_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nvidia cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Nvidia\n",
    "\n",
    "sort_nvidia_1 = df_data_science_salaries['company'].str.contains('Nvidia', na = False)\n",
    "sort_nvidia_2 = df_data_science_salaries['company'].str.contains('nvidia', na = False)\n",
    "sort_nvidia_3 = df_data_science_salaries['company'].str.contains('NVIDIA', na = False)\n",
    "\n",
    "replace_nvidia = df_data_science_salaries[(sort_nvidia_1|sort_nvidia_2|sort_nvidia_3)].company.unique()\n",
    "\n",
    "replace_nvidia\n",
    "\n",
    "# List of Nvidia company name variations that needs standardisation:\n",
    "# NVIDIA\n",
    "# nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_nvidia, value = 'Nvidia', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_nvidia_1|sort_nvidia_2|sort_nvidia_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Oracle\n",
    "\n",
    "sort_oracle_1 = df_data_science_salaries['company'].str.contains('Oracle', na = False)\n",
    "sort_oracle_2 = df_data_science_salaries['company'].str.contains('oracle', na = False)\n",
    "sort_oracle_3 = df_data_science_salaries['company'].str.contains('ORACLE', na = False)\n",
    "\n",
    "replace_oracle = df_data_science_salaries[(sort_oracle_1|sort_oracle_2|sort_oracle_3)].company.unique()\n",
    "\n",
    "replace_oracle\n",
    "# List of Oracle company name variations that needs standardisation:\n",
    "# oracle\n",
    "# ORACLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_oracle, value = 'Oracle', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_oracle_1|sort_oracle_2|sort_oracle_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PayPal cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of PayPal\n",
    "\n",
    "sort_paypal_1 = df_data_science_salaries['company'].str.contains('Paypal', na = False)\n",
    "sort_paypal_2 = df_data_science_salaries['company'].str.contains('paypal', na = False)\n",
    "sort_paypal_3 = df_data_science_salaries['company'].str.contains('PayPal', na = False)\n",
    "\n",
    "replace_paypal = df_data_science_salaries[(sort_paypal_1|sort_paypal_2|sort_paypal_3)].company.unique()\n",
    "\n",
    "replace_paypal\n",
    "# List of PayPal company name variations that needs standardisation:\n",
    "# paypal\n",
    "# Paypal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_paypal, value = 'PayPal', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_paypal_1|sort_paypal_2|sort_paypal_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PWC cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of PWC\n",
    "\n",
    "sort_pwc_1 = df_data_science_salaries['company'].str.contains('PWC', na = False)\n",
    "sort_pwc_2 = df_data_science_salaries['company'].str.contains('pwc', na = False)\n",
    "sort_pwc_3 = df_data_science_salaries['company'].str.contains('PwC', na = False)\n",
    "sort_pwc_4 = df_data_science_salaries['company'].str.contains('Pwc', na = False)\n",
    "\n",
    "replace_pwc = df_data_science_salaries[(sort_pwc_1|sort_pwc_2|sort_pwc_3|sort_pwc_4)].company.unique()\n",
    "\n",
    "replace_pwc\n",
    "\n",
    "# List of PWC company name variations that needs standardisation:\n",
    "# PwC\n",
    "# Strategy by Pw\n",
    "# pwc\n",
    "# Pwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_pwc, value = 'PWC', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_pwc_1|sort_pwc_2|sort_pwc_3|sort_pwc_4)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualcomm cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Qualcomm\n",
    "\n",
    "sort_qualcomm_1 = df_data_science_salaries['company'].str.contains('Qualcomm', na = False)\n",
    "sort_qualcomm_2 = df_data_science_salaries['company'].str.contains('qualcomm', na = False)\n",
    "sort_qualcomm_3 = df_data_science_salaries['company'].str.contains('QUALCOMM', na = False)\n",
    "\n",
    "replace_qualcomm = df_data_science_salaries[(sort_qualcomm_1|sort_qualcomm_2|sort_qualcomm_3)].company.unique()\n",
    "\n",
    "replace_qualcomm\n",
    "\n",
    "# List of Qualcomm company name variations that needs standardisation:\n",
    "# QUALCOMM\n",
    "# Qualcomm Inc\n",
    "# qualcomm\n",
    "# Qualcomm inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_qualcomm, value = 'Qualcomm', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_qualcomm_1|sort_qualcomm_2|sort_qualcomm_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAP cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of SAP\n",
    "\n",
    "sort_sap_1 = df_data_science_salaries['company'].str.contains('SAP', na = False)\n",
    "sort_sap_2 = df_data_science_salaries['company'].str.contains('sap', na = False)\n",
    "sort_sap_3 = df_data_science_salaries['company'].str.contains('Sap', na = False)\n",
    "\n",
    "df_data_science_salaries[(sort_sap_1|sort_sap_2|sort_sap_3)].company.unique()\n",
    "\n",
    "# List of SAP company name variations that needs standardisation:\n",
    "# Sap Concur\n",
    "# SAP Concur\n",
    "# sap\n",
    "# Sap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = ['Sap Concur', 'SAP Concur', 'sap', 'Sap'], value = 'SAP', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_sap_1|sort_sap_2|sort_sap_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salesforce cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Salesforce\n",
    "\n",
    "sort_salesforce_1 = df_data_science_salaries['company'].str.contains('Salesforce', na = False)\n",
    "sort_salesforce_2 = df_data_science_salaries['company'].str.contains('SalesForce', na = False)\n",
    "sort_salesforce_3 = df_data_science_salaries['company'].str.contains('salesforce', na = False)\n",
    "\n",
    "replace_salesforce = df_data_science_salaries[(sort_salesforce_1|sort_salesforce_2|sort_salesforce_3)].company.unique()\n",
    "\n",
    "replace_salesforce\n",
    "\n",
    "# List of Salesforce company name variations that needs standardisation:\n",
    "# salesforce\n",
    "# SalesForce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_salesforce, value = 'Salesforce', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_salesforce_1|sort_salesforce_2|sort_salesforce_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samsung cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Samsung\n",
    "\n",
    "sort_samsung_1 = df_data_science_salaries['company'].str.contains('Samsung', na = False)\n",
    "sort_samsung_2 = df_data_science_salaries['company'].str.contains('samsung', na = False)\n",
    "sort_samsung_3 = df_data_science_salaries['company'].str.contains('SAMSUNG', na = False)\n",
    "\n",
    "replace_samsung = df_data_science_salaries[(sort_samsung_1|sort_samsung_2|sort_samsung_3)].company.unique()\n",
    "\n",
    "replace_samsung\n",
    "\n",
    "# List of Samsung company name variations that needs standardisation:\n",
    "# samsung\n",
    "# Samsung Research America\n",
    "# Samsung Electronics America\n",
    "# SAMSUNG\n",
    "# Samsung research America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_samsung, value = 'Samsung', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_samsung_1|sort_samsung_2|sort_samsung_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ServiceNow cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of ServiceNow\n",
    "\n",
    "sort_servicenow_1 = df_data_science_salaries['company'].str.contains('ServiceNow', na = False)\n",
    "sort_servicenow_2 = df_data_science_salaries['company'].str.contains('Servicenow', na = False)\n",
    "sort_servicenow_3 = df_data_science_salaries['company'].str.contains('servicenow', na = False)\n",
    "\n",
    "replace_servicenow = df_data_science_salaries[(sort_servicenow_1|sort_servicenow_2|sort_servicenow_3)].company.unique()\n",
    "\n",
    "replace_servicenow\n",
    "\n",
    "# List of ServiceNow company name variations that needs standardisation:\n",
    "# servicenow\n",
    "# Servicenow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_servicenow, value = 'ServiceNow', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_servicenow_1|sort_servicenow_2|sort_servicenow_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Mobile cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of T-Mobile\n",
    "\n",
    "sort_tmobile_1 = df_data_science_salaries['company'].str.contains('T-mobile', na = False)\n",
    "sort_tmobile_2 = df_data_science_salaries['company'].str.contains('T-Mobile', na = False)\n",
    "\n",
    "replace_tmobile = df_data_science_salaries[(sort_tmobile_1|sort_tmobile_2)].company.unique()\n",
    "\n",
    "replace_tmobile\n",
    "\n",
    "# List of T-Mobile company name variations that needs standardisation:\n",
    "# T-mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_tmobile, value = 'T-Mobile', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_tmobile_1|sort_tmobile_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesla cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Tesla\n",
    "\n",
    "sort_tesla_1 = df_data_science_salaries['company'].str.contains('Tesla', na = False)\n",
    "sort_tesla_2 = df_data_science_salaries['company'].str.contains('tesla', na = False)\n",
    "\n",
    "replace_tesla = df_data_science_salaries[(sort_tesla_1|sort_tesla_2)].company.unique()\n",
    "\n",
    "replace_tesla\n",
    "\n",
    "# List of Tesla company name variations that needs standardisation:\n",
    "# tesla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_tesla, value = 'Tesla', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_tesla_1|sort_tesla_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Twitter\n",
    "\n",
    "sort_twitter_1 = df_data_science_salaries['company'].str.contains('Twitter', na = False)\n",
    "sort_twitter_2 = df_data_science_salaries['company'].str.contains('twitter', na = False)\n",
    "\n",
    "replace_twitter = df_data_science_salaries[(sort_twitter_1|sort_twitter_2)].company.unique()\n",
    "\n",
    "replace_twitter\n",
    "\n",
    "# List of Twitter company name variations that needs standardisation:\n",
    "# twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_twitter, value = 'Twitter', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_twitter_1|sort_twitter_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uber cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Uber\n",
    "\n",
    "sort_uber_1 = df_data_science_salaries['company'].str.contains('Uber', na = False)\n",
    "sort_uber_2 = df_data_science_salaries['company'].str.contains('uber', na = False)\n",
    "sort_uber_3 = df_data_science_salaries['company'].str.contains('UBER', na = False)\n",
    "\n",
    "replace_uber = df_data_science_salaries[(sort_uber_1|sort_uber_2|sort_uber_3)].company.unique()\n",
    "\n",
    "replace_uber\n",
    "\n",
    "# List of Uber company name variations that needs standardisation:\n",
    "# UBER\n",
    "# uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_uber, value = 'Uber', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_uber_1|sort_uber_2|sort_uber_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VMware cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of VMware\n",
    "\n",
    "sort_vmware_1 = df_data_science_salaries['company'].str.contains('vmware', na = False)\n",
    "sort_vmware_2 = df_data_science_salaries['company'].str.contains('VMware', na = False)\n",
    "sort_vmware_3 = df_data_science_salaries['company'].str.contains('VMWare', na = False)\n",
    "sort_vmware_4 = df_data_science_salaries['company'].str.contains('Vmware', na = False)\n",
    "sort_vmware_5 = df_data_science_salaries['company'].str.contains('VmWare', na = False)\n",
    "\n",
    "replace_vmware = df_data_science_salaries[(sort_vmware_1|sort_vmware_2|sort_vmware_3|sort_vmware_4|sort_vmware_5)].company.unique()\n",
    "\n",
    "replace_vmware\n",
    "\n",
    "# List of VMware company name variations that needs standardisation:\n",
    "# VMWare\n",
    "# vmware\n",
    "# Vmware\n",
    "# VmWare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_vmware, value = 'VMware', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_vmware_1|sort_vmware_2|sort_vmware_3|sort_vmware_4|sort_vmware_5)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visa cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Visa\n",
    "\n",
    "sort_visa_1 = df_data_science_salaries['company'].str.contains('visa', na = False)\n",
    "sort_visa_2 = df_data_science_salaries['company'].str.contains('Visa', na = False)\n",
    "sort_visa_3 = df_data_science_salaries['company'].str.contains('VISA', na = False)\n",
    "\n",
    "replace_visa = df_data_science_salaries[(sort_visa_1|sort_visa_2|sort_visa_3)].company.unique()\n",
    "\n",
    "replace_visa\n",
    "\n",
    "# List of Visa company name variations that needs standardisation:\n",
    "# Visa Inc\n",
    "# VISA\n",
    "# visa\n",
    "# Visa inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_visa, value = 'Visa', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_visa_1|sort_visa_2|sort_visa_3)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walmart cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Walmart\n",
    "\n",
    "sort_walmart_1 = df_data_science_salaries['company'].str.contains('walmart', na = False)\n",
    "sort_walmart_2 = df_data_science_salaries['company'].str.contains('Walmart', na = False)\n",
    "\n",
    "replace_walmart = df_data_science_salaries[(sort_walmart_1|sort_walmart_2)].company.unique()\n",
    "\n",
    "replace_walmart\n",
    "\n",
    "# List of Walmart company name variations that needs standardisation:\n",
    "# Walmart Labs\n",
    "# Walmart labs\n",
    "# walmart labs\n",
    "# walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_walmart, value = 'Walmart', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_walmart_1|sort_walmart_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wayfair cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Wayfair\n",
    "\n",
    "sort_wayfair_1 = df_data_science_salaries['company'].str.contains('wayfair', na = False)\n",
    "sort_wayfair_2 = df_data_science_salaries['company'].str.contains('Wayfair', na = False)\n",
    "\n",
    "replace_wayfair = df_data_science_salaries[(sort_wayfair_1|sort_wayfair_2)].company.unique()\n",
    "\n",
    "replace_wayfair\n",
    "\n",
    "# List of Wayfair company name variations that needs standardisation:\n",
    "# wayfair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_wayfair, value = 'Wayfair', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_wayfair_1|sort_wayfair_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workday cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Workday\n",
    "\n",
    "sort_workday_1 = df_data_science_salaries['company'].str.contains('workday', na = False)\n",
    "sort_workday_2 = df_data_science_salaries['company'].str.contains('Workday', na = False)\n",
    "\n",
    "replace_workday = df_data_science_salaries[(sort_workday_1|sort_workday_2)].company.unique()\n",
    "\n",
    "replace_workday\n",
    "\n",
    "# List of Workday company name variations that needs standardisation:\n",
    "# workday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_workday, value = 'Workday', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_workday_1|sort_workday_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Yahoo\n",
    "\n",
    "sort_yahoo_1 = df_data_science_salaries['company'].str.contains('yahoo', na = False)\n",
    "sort_yahoo_2 = df_data_science_salaries['company'].str.contains('Yahoo', na = False)\n",
    "\n",
    "replace_yahoo = df_data_science_salaries[(sort_yahoo_1|sort_yahoo_2)].company.unique()\n",
    "\n",
    "replace_yahoo\n",
    "\n",
    "# List of Yahoo company name variations that needs standardisation:\n",
    "# yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_yahoo, value = 'Yahoo', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_yahoo_1|sort_yahoo_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yandex cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Yandex\n",
    "\n",
    "sort_yandex_1 = df_data_science_salaries['company'].str.contains('yandex', na = False)\n",
    "sort_yandex_2 = df_data_science_salaries['company'].str.contains('Yandex', na = False)\n",
    "\n",
    "replace_yandex = df_data_science_salaries[(sort_yandex_1|sort_yandex_2)].company.unique()\n",
    "\n",
    "replace_yandex\n",
    "\n",
    "# List of Yandex company name variations that needs standardisation:\n",
    "# yandex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_yandex, value = 'Yandex', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_yandex_1|sort_yandex_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Yelp\n",
    "\n",
    "sort_yelp_1 = df_data_science_salaries['company'].str.contains('yelp', na = False)\n",
    "sort_yelp_2 = df_data_science_salaries['company'].str.contains('Yelp', na = False)\n",
    "\n",
    "replace_yelp = df_data_science_salaries[(sort_yelp_1|sort_yelp_2)].company.unique()\n",
    "\n",
    "replace_yelp\n",
    "\n",
    "# List of Yelp company name variations that needs standardisation:\n",
    "# yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_yelp, value = 'Yelp', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_yelp_1|sort_yelp_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zillow cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for all variations of Zillow\n",
    "\n",
    "sort_zillow_1 = df_data_science_salaries['company'].str.contains('Zillow', na = False)\n",
    "sort_zillow_2 = df_data_science_salaries['company'].str.contains('zillow', na = False)\n",
    "\n",
    "replace_zillow = df_data_science_salaries[(sort_zillow_1|sort_zillow_2)].company.unique()\n",
    "\n",
    "replace_zillow\n",
    "\n",
    "# List of Zillow company name variations that needs standardisation:\n",
    "# Zillow Group\n",
    "# zillow\n",
    "# zillow group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing values\n",
    "\n",
    "df_data_science_salaries['company'].replace(to_replace = replace_zillow, value = 'Zillow', inplace= True)\n",
    "\n",
    "#Double checking\n",
    "df_data_science_salaries[(sort_zillow_1|sort_zillow_2)].company.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change location into state and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 500)\n",
    "\n",
    "df_data_science_salaries['location'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = df_data_science_salaries['location'].str.split(',', n = 2, expand = True)\n",
    "#Delimiting the location column by commas into city, state and country\n",
    "test1[2].fillna(value = 'USA', inplace = True)\n",
    "#Filling the empty rows under the 2nd index column with USA because the data omits USA under country\n",
    "test1.head(200)\n",
    "\n",
    "df_data_science_salaries['State'] = test1[1]\n",
    "#Adding new column header 'State' using index column 1 of the delimited dataframe\n",
    "df_data_science_salaries['Country'] = test1[2]\n",
    "#Adding new column header 'State' using index column 2 of the delimited dataframe\n",
    "df_data_science_salaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping columns Gender to Education because of too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_science_salaries = df_data_science_salaries.drop(df_data_science_salaries.loc[:, 'gender': 'Education'].columns, axis = 1)\n",
    "#Dropping columns that are of no use to our analysis\n",
    "df_data_science_salaries = df_data_science_salaries.drop(['location'], axis = 1)\n",
    "#Dropping location since we already have the State and Country columns\n",
    "df_data_science_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting csv file\n",
    "\n",
    "df_data_science_salaries_cleaned = df_data_science_salaries.copy()\n",
    "\n",
    "df_data_science_salaries_cleaned.to_csv(r'C:\\Users\\dani3\\Desktop\\Applied Data Science Course\\Data Analytics PCDSI0122 - DS102\\Assignment\\Final\\Data Science Salaries(cleaned).csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('applied_data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c787ffc59f184150a52190fefe6a6b2e84ea9e55349484aa0b789b3d99c2a77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
